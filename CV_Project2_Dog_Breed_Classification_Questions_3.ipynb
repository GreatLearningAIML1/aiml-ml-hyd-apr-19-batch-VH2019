{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CV_Project2_Dog_Breed_Classification_Questions-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvsAYnxSmNEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=[]\n",
        "while (1):\n",
        "  a.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2kIWaR5ZpKlJ"
      },
      "source": [
        "## Dog Breed Classification\n",
        "\n",
        "In this project we will use traditional CNN, CNN with data augmentation and finally transfer Learning by VGG16 model with weights pre-trained on Imagenet to solve the dog breed classification problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F7MDmaAw2xGO"
      },
      "source": [
        "### Load Dataset Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1q2zzIaUprk_"
      },
      "source": [
        "Now, upload the given dataset file shared with you in your google drive and give its path for the below given `project_path` variable. For example, a path is given below according to the file path in our google drive. You need to change this to match the path of yours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rydR_j8lqUei"
      },
      "source": [
        "Run the below code to extract all the images in the train.zip files given in the dataset. We are going to use these images as train and validation sets and their labels in further steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZWpQv1OwqYK",
        "outputId": "030475c8-0ba7-4be5-c6a1-89f6ae9f8e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39yiJKHjowVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/drive/My Drive/AIML/DogBreed_Classification'  #change dir to your project folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br_6mwRmowY4",
        "colab_type": "code",
        "outputId": "86fed18f-1f1a-4b47-eefb-3bf45268c8e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  labels.csv  \u001b[01;34msample_data\u001b[0m/  sample_submission.csv  \u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fVhB9OopxFbX",
        "outputId": "ca2d0a1c-7657-40c1-928f-809bc755089e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (16.0, 4.0) # Set default figure size"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2tG4ynbp4iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TENSORBOARD_SUMMARIES_DIR = '/tmp/DogBreeds_classifier_logs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3350WZM4w4EL",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/My Drive/AIML/DogBreed_Classification/'+'train.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3NHq1iBCfFjE"
      },
      "source": [
        "Repeat the same step for test.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYu22UMKynZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/My Drive/AIML/DogBreed_Classification/'+'test.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jnUMhQrDfJmz"
      },
      "source": [
        "Repeat the same step for sample_submission.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4PyTxE8q2jLf",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/My Drive/AIML/DogBreed_Classification/'+'sample_submission.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2G9RIxB-fOLT"
      },
      "source": [
        "Repeat the same step for labels.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rXtnEoEixbgi",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/My Drive/AIML/DogBreed_Classification/'+'labels.csv.zip', 'r') as z:\n",
        "  z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sJc1lVrW_jmL"
      },
      "source": [
        "After this process, we will have 4 files - Train folder, test folder and labels.csv and sample_submission.csv as part of your google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aYmJKmDqqpng"
      },
      "source": [
        "### Read labels.csv file using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WmlJ2VMY96IZ",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "db_labels=pd.read_csv('labels.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QP8YAzQvqyK-"
      },
      "source": [
        "### Print the count of each category of Dogs given in the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-reQcANI5bT9",
        "colab_type": "code",
        "outputId": "ec2398af-5754-406a-bbd4-3f193e6e45b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "db_labels.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
              "      <td>boston_bull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
              "      <td>dingo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
              "      <td>pekinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
              "      <td>bluetick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
              "      <td>golden_retriever</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 id             breed\n",
              "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
              "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
              "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
              "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
              "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3L2naXlr96Im",
        "outputId": "770544fc-cfa4-4ea2-dbf3-e4fc8e014c64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "db_labels.count()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id       10222\n",
              "breed    10222\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CLm3W5RN96Ir",
        "outputId": "96e950cf-d856-4adb-fa6d-2505334d63c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "db_labels_x=db_labels['breed'].value_counts()\n",
        "db_labels_x.head(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scottish_deerhound      126\n",
              "maltese_dog             117\n",
              "afghan_hound            116\n",
              "entlebucher             115\n",
              "bernese_mountain_dog    114\n",
              "shih-tzu                112\n",
              "pomeranian              111\n",
              "great_pyrenees          111\n",
              "basenji                 110\n",
              "samoyed                 109\n",
              "Name: breed, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WI94_Qcc0D4M"
      },
      "source": [
        "### Get one-hot encodings of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q48iAcY196I3",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnspBlPRlkpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_target=pd.Series(db_labels['breed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7EXvSGwluHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot=pd.get_dummies(y_target,sparse=True)\n",
        "y_target=np.asarray(one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VWaJ9naXfoiU"
      },
      "source": [
        "## Preparing training dataset\n",
        "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
        "2. Create 2 variables <br> \n",
        "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
        "     b.  y_train - Corresponding label of the dog <br>\n",
        "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
        "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ulS1yb4dh9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 128\n",
        "img_cols = 128\n",
        "num_channel = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxRHvRSHl9jS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "ids=db_labels['id']\n",
        "x_train=[]\n",
        "y_train=y_target\n",
        "#print(y_train[1].shape)\n",
        "\n",
        "for id in ids:\n",
        "    img = cv2.imread('./train/{}.jpg'.format(id))\n",
        "    x_train.append(cv2.resize(img,(img_rows,img_cols)))\n",
        "    \n",
        "x_train=np.array(x_train,np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUH7UF40l9mB",
        "colab_type": "code",
        "outputId": "f7d6182b-1698-4a0b-c454-3c8797f03e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10222, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB286yxInZ6n",
        "colab_type": "code",
        "outputId": "cc56562f-8b2e-4a74-c9c8-1a17496e48e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10222, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6ioWDEgElBOs"
      },
      "source": [
        "Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd6cnws1A4-0",
        "colab_type": "code",
        "outputId": "95b0d278-4e26-4f0b-becf-795784cb0242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train = (np.array(x_train, np.float32) /255)   # /= 255 for normolisation\n",
        "print (x_train.shape)\n",
        "\n",
        "#y_train = np.array(db_labels)\n",
        "\n",
        "#print(y_train.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10222, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bdCXuAE11gZL"
      },
      "source": [
        "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kpWx-pgV96Jv",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.30, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBKc5dViFrTK",
        "colab_type": "code",
        "outputId": "9387d040-c304-4514-82d0-6f8d8f9796c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print (x_train.shape)\n",
        "print (y_train.shape)\n",
        "print (x_test.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7155, 128, 128, 3)\n",
            "(7155, 120)\n",
            "(3067, 128, 128, 3)\n",
            "(3067, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkL-N1jDsU8m"
      },
      "source": [
        "### Loading the test data\n",
        "Read the id column from the samples_submission.csv and store it in test_img"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itt-FWQDFobj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_s=pd.read_csv('sample_submission.csv')\n",
        "test_img=sample_s['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vVg_UAd4MBb",
        "colab_type": "code",
        "outputId": "9c20ae51-c34e-4bd8-9175-8bb91eb32251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_img[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'000621fb3cbb32d8935728e48679680e'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DEJqZIMbm0Jo"
      },
      "source": [
        "Run the below code to load the test image files in x_test_feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zf7n4WG-b3Hv",
        "outputId": "f8e363c8-79cf-48bd-8b51-a121f73e6d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img_rows=128\n",
        "img_cols=128\n",
        "x_test_feature = []\n",
        "i = 0 # initialization\n",
        "for f in tqdm(test_img.values): # f for format ,jpg\n",
        "    img = cv2.imread('./test/{}.jpg'.format(f))\n",
        "    img_resize = cv2.resize(img, (img_rows, img_cols)) \n",
        "    x_test_feature.append(img_resize)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10357/10357 [00:31<00:00, 328.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9My6qSyDnE-_"
      },
      "source": [
        "Normalize the test data and convert it into 4 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43RiwTsvp8f1",
        "colab_type": "code",
        "outputId": "6b8a87e2-c67e-4ca2-9d0c-7b2d79dae09a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test_feature=np.array(x_test_feature,np.float32)\n",
        "\n",
        "x_test_feature.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10357, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD22-LQXjMS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_feature=x_test_feature/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKYKAZ78IPwt",
        "colab_type": "code",
        "outputId": "bba64e23-4c97-494f-b07c-a7c1ba10123b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (x_train.shape,x_test.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7155, 128, 128, 3) (3067, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHIPqxzfjSBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cba8312-785d-4c0d-f547-dfccc7866d1c"
      },
      "source": [
        "print(x_test_feature.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10357, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zKezNJVMsocP"
      },
      "source": [
        "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
        "\n",
        "1. Add a Dense layer with 256 neurons with `relu` activation\n",
        "\n",
        "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D2jxTY2S96J4",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalMaxPooling2D,Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENa7P76GQDf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes=120\n",
        "batch_size=128\n",
        "epochs=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Lda_YZJ2XO",
        "colab_type": "code",
        "outputId": "33987857-1daa-40a4-d4c0-2ca430fb94d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(5,5),input_shape=x_train.shape[1:],activation='relu',padding='same'))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "\n",
        "model.add(Conv2D(32,(3,3),padding='same',activation='relu'))\n",
        "model.add(BatchNormalization(axis=3))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(120))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EV7TgzTRzFg",
        "colab_type": "code",
        "outputId": "d820eeb9-94c9-4e1e-e384-6532246033c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 32)      2432      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               8388864   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 120)               0         \n",
            "=================================================================\n",
            "Total params: 8,431,640\n",
            "Trainable params: 8,431,512\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ui8EXw6_oqpR"
      },
      "source": [
        "### Use batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDgqKRWUmCvx",
        "colab_type": "code",
        "outputId": "dc4a7ca8-f4e5-484f-aa6a-fd65e0108e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7155, 128, 128, 3)\n",
            "(7155, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IriIc37NozbK",
        "outputId": "bd98d654-c525-4be3-e606-dd26a3e64ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/10\n",
            "7155/7155 [==============================] - 10s 1ms/step - loss: 5.6174 - acc: 0.0095\n",
            "Epoch 2/10\n",
            "7155/7155 [==============================] - 3s 411us/step - loss: 4.7816 - acc: 0.0130\n",
            "Epoch 3/10\n",
            "7155/7155 [==============================] - 3s 412us/step - loss: 4.7678 - acc: 0.0168\n",
            "Epoch 4/10\n",
            "7155/7155 [==============================] - 3s 410us/step - loss: 4.7530 - acc: 0.0183\n",
            "Epoch 5/10\n",
            "7155/7155 [==============================] - 3s 416us/step - loss: 4.7187 - acc: 0.0189\n",
            "Epoch 6/10\n",
            "7155/7155 [==============================] - 3s 407us/step - loss: 4.6824 - acc: 0.0268\n",
            "Epoch 7/10\n",
            "7155/7155 [==============================] - 3s 407us/step - loss: 4.6174 - acc: 0.0348\n",
            "Epoch 8/10\n",
            "7155/7155 [==============================] - 3s 404us/step - loss: 4.5435 - acc: 0.0401\n",
            "Epoch 9/10\n",
            "7155/7155 [==============================] - 3s 403us/step - loss: 4.4639 - acc: 0.0486\n",
            "Epoch 10/10\n",
            "7155/7155 [==============================] - 3s 406us/step - loss: 4.3782 - acc: 0.0576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe15d358550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z8hWaKmjoz69"
      },
      "source": [
        "#The model accuracy is very poor !!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "agJKkc6xtKiq"
      },
      "source": [
        "### Use Data Augmentation in the above model to see if the accuracy improves\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "31Mn8qnZb3Ru",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDLQVFDP96KI",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False, \n",
        "    samplewise_center=False, \n",
        "    featurewise_std_normalization=False,\n",
        "    samplewise_std_normalization=False,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sssbaTfxlkk"
      },
      "source": [
        "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
        "\n",
        "You need to use train_datagen.flow() and val_datagen.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84HOCOodw7Fg",
        "colab_type": "code",
        "outputId": "e88efaf6-da8a-42d8-ee5d-0b3592156670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3067, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FokGdSdQvoaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = datagen.flow(x_train, y_train, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4rLeUzmw5Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_generator = datagen.flow(x_test, y_test, batch_size=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3VHXRIuy22h",
        "colab_type": "code",
        "outputId": "e90dc6f6-e12d-43e7-c1c2-0e75e4e12be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout\n",
        "\n",
        "#Initialize model, reshape & normalize data\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Add first convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(50, #Number of filters \n",
        "                                 kernel_size=(5,5), #Size of the filter\n",
        "                                 activation='relu'\n",
        "                                , input_shape=(128,128,3)))\n",
        "\n",
        "\n",
        "\n",
        "#Add second  convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(50, #Number of filters \n",
        "                                 kernel_size=(3,3), #Size of the filter\n",
        "                                 activation='relu'\n",
        "                                , input_shape=(128,128,3)))\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "#Flatten the output\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "#Dense layer\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "\n",
        "#Dense layer\n",
        "model.add(tf.keras.layers.Dense(120, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 124, 124, 50)      3800      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 50)      22550     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 122, 122, 50)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 744200)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               190515456 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 120)               30840     \n",
            "=================================================================\n",
            "Total params: 190,572,646\n",
            "Trainable params: 190,572,646\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lADITd-BRGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TVFQJZw3x4-C"
      },
      "source": [
        "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP_Pt2Ynz7_8",
        "colab_type": "code",
        "outputId": "1be58b7b-fa80-4c4e-d6cb-a1fc3e235584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7155, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XxTJ-WPzGu3",
        "colab_type": "code",
        "outputId": "10f53563-4dcb-4b66-fb69-879e97ca3c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "source": [
        "# Set up the generator\n",
        "#Train the model\n",
        "history = model.fit_generator(train_generator, \n",
        "                             validation_data=val_generator , use_multiprocessing=True,\n",
        "                     steps_per_epoch=len(x_train/50), epochs=10)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 3.8577 - acc: 0.1329Epoch 1/10\n",
            "7155/7155 [==============================] - 1498s 209ms/step - loss: 3.8575 - acc: 0.1330 - val_loss: 5.3490 - val_acc: 0.0597\n",
            "Epoch 2/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 2.2600 - acc: 0.4285Epoch 1/10\n",
            "7155/7155 [==============================] - 1479s 207ms/step - loss: 2.2599 - acc: 0.4286 - val_loss: 7.2782 - val_acc: 0.0734\n",
            "Epoch 3/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 1.5213 - acc: 0.5997Epoch 1/10\n",
            "7155/7155 [==============================] - 1517s 212ms/step - loss: 1.5213 - acc: 0.5997 - val_loss: 8.1973 - val_acc: 0.0694\n",
            "Epoch 4/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 1.1712 - acc: 0.6876Epoch 1/10\n",
            "7155/7155 [==============================] - 1509s 211ms/step - loss: 1.1712 - acc: 0.6876 - val_loss: 9.3299 - val_acc: 0.0714\n",
            "Epoch 5/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 0.9733 - acc: 0.7381Epoch 1/10\n",
            "7155/7155 [==============================] - 1519s 212ms/step - loss: 0.9733 - acc: 0.7381 - val_loss: 10.4336 - val_acc: 0.0740\n",
            "Epoch 6/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 0.8475 - acc: 0.7721Epoch 1/10\n",
            "7155/7155 [==============================] - 1514s 212ms/step - loss: 0.8475 - acc: 0.7721 - val_loss: 11.2301 - val_acc: 0.0691\n",
            "Epoch 7/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 0.7661 - acc: 0.7945Epoch 1/10\n",
            "7155/7155 [==============================] - 1514s 212ms/step - loss: 0.7661 - acc: 0.7945 - val_loss: 11.9947 - val_acc: 0.0756\n",
            "Epoch 8/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 0.7039 - acc: 0.8111Epoch 1/10\n",
            "7155/7155 [==============================] - 1516s 212ms/step - loss: 0.7039 - acc: 0.8111 - val_loss: 12.1884 - val_acc: 0.0711\n",
            "Epoch 9/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 0.6537 - acc: 0.8254Epoch 1/10\n",
            "7155/7155 [==============================] - 1520s 212ms/step - loss: 0.6537 - acc: 0.8254 - val_loss: 13.4475 - val_acc: 0.0730\n",
            "Epoch 10/10\n",
            "7154/7155 [============================>.] - ETA: 0s - loss: 0.6266 - acc: 0.8332Epoch 1/10\n",
            "7155/7155 [==============================] - 1513s 211ms/step - loss: 0.6266 - acc: 0.8332 - val_loss: 13.6686 - val_acc: 0.0796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J1K2MqHbuPUa",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q2zmLztqo5DY"
      },
      "source": [
        "# Model accuracy is still poor!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rSTATrhsAo7L"
      },
      "source": [
        "### Lets use Transfer Learning\n",
        "\n",
        "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zy5JdbW6pIvD"
      },
      "source": [
        "Use the below code to load VGG16 weights trained on ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yrqs0zg7ApNw",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUtROL7bZj6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzEUMJ5rZlMv",
        "colab_type": "code",
        "outputId": "ae7c9980-43a5-4da4-dd69-a1897f360a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCe1hwYR8I1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the model with the pre-trained weights (no top)\n",
        "base_model= VGG16(weights=('/content/drive/My Drive/vgg16_weights_tf_dim_ordering_tf_kernels_notop1.h5'),\n",
        "                 include_top=False, pooling='avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EItOlRBGpV_A"
      },
      "source": [
        "Print the summary of the base_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lQsEBgnlpHjH",
        "outputId": "96c25240-6be7-40b5-a1e7-c8699fa866de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fHpeOyW0qauW"
      },
      "source": [
        "### Add the following classification layers to the imported VGG Model <br>\n",
        "1. Flatten Layer\n",
        "2. Dense layer with 1024 neurons with activation as Relu\n",
        "3. Dense layer with 256 neurons with activation as Relu\n",
        "4. Dense layer with 120 neurons with activation as Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LeQem0pHITIj"
      },
      "source": [
        "### Make all the layers in the base_model (VGG16) to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7w9CSPvIRnX",
        "outputId": "c04d3e6b-c7e8-4a0c-df32-fa94bebfb886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout \n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "model_transfer = Sequential()\n",
        "model_transfer.add(Dense(1024,input_dim=512, activation='relu'))\n",
        "model_transfer.add(BatchNormalization())\n",
        "model_transfer.add(Dropout(0.50))\n",
        "model_transfer.add(Dense(256, activation='relu'))\n",
        "model_transfer.add(BatchNormalization())\n",
        "model_transfer.add(Dropout(0.40))\n",
        "model_transfer.add(Dense(256, activation='relu'))\n",
        "model_transfer.add(BatchNormalization())\n",
        "model_transfer.add(Dropout(0.30))\n",
        "\n",
        "model_transfer.add(Dense(120,activation='softmax'))\n",
        "model_transfer.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckr3tqJo8nDN",
        "colab_type": "code",
        "outputId": "5f68f3c2-2c50-42dc-e063-67b8165f4244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "source": [
        "#Freezing layers in the model which don't have 'dense' in their name\n",
        "for layer in base_model.layers:\n",
        "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False\n",
        "\n",
        "#Module to print colourful statements\n",
        "from termcolor import colored\n",
        "\n",
        "#Check which layers have been frozen \n",
        "for layer in base_model.layers:\n",
        "  print (colored(layer.name, 'blue'))\n",
        "  print (colored(layer.trainable, 'red'))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34minput_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock1_conv1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock1_conv2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock1_pool\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock2_conv1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock2_conv2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock2_pool\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock3_conv1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock3_conv2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock3_conv3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock3_pool\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock4_conv1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock4_conv2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock4_conv3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock4_pool\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock5_conv1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock5_conv2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock5_conv3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mblock5_pool\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mglobal_average_pooling2d_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kj-BwqgfIkdv"
      },
      "source": [
        "### Fit and compile the model with batch_size = 128 and epochs = 10 and execute the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YD5fAgVQIpKZ"
      },
      "source": [
        "Try to get training and validation accuracy to be more than 90%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SZk2SWvjIoRP",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = base_model.predict(x_train)\n",
        "\n",
        "x_test = base_model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVuMttE1azzW",
        "colab_type": "code",
        "outputId": "cc349cac-fcca-4b9a-9fee-b278bedbf44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "output_transfer = model_transfer.fit(x_train, y_train, \n",
        "                                      validation_data=(x_test, y_test),\n",
        "                                      batch_size=300, epochs=150, verbose=1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7155 samples, validate on 3067 samples\n",
            "Epoch 1/150\n",
            "7155/7155 [==============================] - 1s 151us/step - loss: 5.4284 - acc: 0.0131 - val_loss: 4.6107 - val_acc: 0.0437\n",
            "Epoch 2/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 4.7208 - acc: 0.0447 - val_loss: 4.2460 - val_acc: 0.0783\n",
            "Epoch 3/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 4.3487 - acc: 0.0791 - val_loss: 3.9991 - val_acc: 0.1043\n",
            "Epoch 4/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 4.0111 - acc: 0.1058 - val_loss: 3.8143 - val_acc: 0.1311\n",
            "Epoch 5/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 3.7935 - acc: 0.1346 - val_loss: 3.6890 - val_acc: 0.1448\n",
            "Epoch 6/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 3.5702 - acc: 0.1597 - val_loss: 3.5486 - val_acc: 0.1722\n",
            "Epoch 7/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 3.4376 - acc: 0.1855 - val_loss: 3.4645 - val_acc: 0.1845\n",
            "Epoch 8/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 3.3064 - acc: 0.2034 - val_loss: 3.4538 - val_acc: 0.1797\n",
            "Epoch 9/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 3.2043 - acc: 0.2198 - val_loss: 3.3924 - val_acc: 0.1963\n",
            "Epoch 10/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 3.1219 - acc: 0.2377 - val_loss: 3.3948 - val_acc: 0.1920\n",
            "Epoch 11/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 2.9918 - acc: 0.2555 - val_loss: 3.3557 - val_acc: 0.2005\n",
            "Epoch 12/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.9636 - acc: 0.2622 - val_loss: 3.3326 - val_acc: 0.2077\n",
            "Epoch 13/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 2.8744 - acc: 0.2804 - val_loss: 3.2785 - val_acc: 0.2168\n",
            "Epoch 14/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 2.8388 - acc: 0.2894 - val_loss: 3.2516 - val_acc: 0.2243\n",
            "Epoch 15/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 2.7605 - acc: 0.2960 - val_loss: 3.2429 - val_acc: 0.2256\n",
            "Epoch 16/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.7205 - acc: 0.3061 - val_loss: 3.2758 - val_acc: 0.2168\n",
            "Epoch 17/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 2.6612 - acc: 0.3210 - val_loss: 3.2417 - val_acc: 0.2253\n",
            "Epoch 18/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 2.6410 - acc: 0.3241 - val_loss: 3.3014 - val_acc: 0.2185\n",
            "Epoch 19/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 2.5725 - acc: 0.3352 - val_loss: 3.2456 - val_acc: 0.2260\n",
            "Epoch 20/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.5469 - acc: 0.3421 - val_loss: 3.2685 - val_acc: 0.2260\n",
            "Epoch 21/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 2.5109 - acc: 0.3451 - val_loss: 3.3603 - val_acc: 0.2116\n",
            "Epoch 22/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.4567 - acc: 0.3588 - val_loss: 3.2532 - val_acc: 0.2321\n",
            "Epoch 23/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.4271 - acc: 0.3602 - val_loss: 3.2638 - val_acc: 0.2276\n",
            "Epoch 24/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.3999 - acc: 0.3688 - val_loss: 3.2671 - val_acc: 0.2286\n",
            "Epoch 25/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 2.3446 - acc: 0.3824 - val_loss: 3.3013 - val_acc: 0.2217\n",
            "Epoch 26/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.3103 - acc: 0.3965 - val_loss: 3.2882 - val_acc: 0.2260\n",
            "Epoch 27/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.3006 - acc: 0.3964 - val_loss: 3.3461 - val_acc: 0.2149\n",
            "Epoch 28/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.2733 - acc: 0.3992 - val_loss: 3.2878 - val_acc: 0.2286\n",
            "Epoch 29/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.2387 - acc: 0.4060 - val_loss: 3.2262 - val_acc: 0.2338\n",
            "Epoch 30/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.1894 - acc: 0.4226 - val_loss: 3.2912 - val_acc: 0.2289\n",
            "Epoch 31/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.1573 - acc: 0.4224 - val_loss: 3.3177 - val_acc: 0.2299\n",
            "Epoch 32/150\n",
            "7155/7155 [==============================] - 0s 41us/step - loss: 2.1680 - acc: 0.4168 - val_loss: 3.3159 - val_acc: 0.2273\n",
            "Epoch 33/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.1231 - acc: 0.4326 - val_loss: 3.3981 - val_acc: 0.2233\n",
            "Epoch 34/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.1198 - acc: 0.4334 - val_loss: 3.4239 - val_acc: 0.2224\n",
            "Epoch 35/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 2.0870 - acc: 0.4356 - val_loss: 3.4271 - val_acc: 0.2260\n",
            "Epoch 36/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 2.0592 - acc: 0.4509 - val_loss: 3.3287 - val_acc: 0.2338\n",
            "Epoch 37/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 2.0173 - acc: 0.4555 - val_loss: 3.4215 - val_acc: 0.2237\n",
            "Epoch 38/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.9949 - acc: 0.4583 - val_loss: 3.3937 - val_acc: 0.2204\n",
            "Epoch 39/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.9773 - acc: 0.4541 - val_loss: 3.4237 - val_acc: 0.2198\n",
            "Epoch 40/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.9549 - acc: 0.4626 - val_loss: 3.4056 - val_acc: 0.2289\n",
            "Epoch 41/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.9425 - acc: 0.4713 - val_loss: 3.3875 - val_acc: 0.2246\n",
            "Epoch 42/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.9285 - acc: 0.4710 - val_loss: 3.4915 - val_acc: 0.2282\n",
            "Epoch 43/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.9095 - acc: 0.4781 - val_loss: 3.4421 - val_acc: 0.2361\n",
            "Epoch 44/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.8963 - acc: 0.4734 - val_loss: 3.4431 - val_acc: 0.2308\n",
            "Epoch 45/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.8534 - acc: 0.4921 - val_loss: 3.4350 - val_acc: 0.2338\n",
            "Epoch 46/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.8626 - acc: 0.4925 - val_loss: 3.4802 - val_acc: 0.2201\n",
            "Epoch 47/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.8344 - acc: 0.4999 - val_loss: 3.4864 - val_acc: 0.2308\n",
            "Epoch 48/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.8054 - acc: 0.5059 - val_loss: 3.4481 - val_acc: 0.2335\n",
            "Epoch 49/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.7775 - acc: 0.5059 - val_loss: 3.4986 - val_acc: 0.2276\n",
            "Epoch 50/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.7716 - acc: 0.5045 - val_loss: 3.5086 - val_acc: 0.2240\n",
            "Epoch 51/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.7511 - acc: 0.5125 - val_loss: 3.4977 - val_acc: 0.2292\n",
            "Epoch 52/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.7452 - acc: 0.5048 - val_loss: 3.5098 - val_acc: 0.2233\n",
            "Epoch 53/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.7315 - acc: 0.5136 - val_loss: 3.5354 - val_acc: 0.2308\n",
            "Epoch 54/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.7194 - acc: 0.5187 - val_loss: 3.5896 - val_acc: 0.2276\n",
            "Epoch 55/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.6949 - acc: 0.5262 - val_loss: 3.6178 - val_acc: 0.2172\n",
            "Epoch 56/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.6929 - acc: 0.5263 - val_loss: 3.7096 - val_acc: 0.2116\n",
            "Epoch 57/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.6889 - acc: 0.5258 - val_loss: 3.5267 - val_acc: 0.2312\n",
            "Epoch 58/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.6420 - acc: 0.5360 - val_loss: 3.5715 - val_acc: 0.2224\n",
            "Epoch 59/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.6466 - acc: 0.5332 - val_loss: 3.5409 - val_acc: 0.2292\n",
            "Epoch 60/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.6150 - acc: 0.5385 - val_loss: 3.6101 - val_acc: 0.2341\n",
            "Epoch 61/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.6156 - acc: 0.5416 - val_loss: 3.6492 - val_acc: 0.2240\n",
            "Epoch 62/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.5809 - acc: 0.5488 - val_loss: 3.6518 - val_acc: 0.2220\n",
            "Epoch 63/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.5762 - acc: 0.5474 - val_loss: 3.6969 - val_acc: 0.2201\n",
            "Epoch 64/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.5740 - acc: 0.5560 - val_loss: 3.7059 - val_acc: 0.2181\n",
            "Epoch 65/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.5662 - acc: 0.5586 - val_loss: 3.7390 - val_acc: 0.2106\n",
            "Epoch 66/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.5551 - acc: 0.5579 - val_loss: 3.7671 - val_acc: 0.2158\n",
            "Epoch 67/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.5487 - acc: 0.5599 - val_loss: 3.6351 - val_acc: 0.2276\n",
            "Epoch 68/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.5235 - acc: 0.5688 - val_loss: 3.6164 - val_acc: 0.2312\n",
            "Epoch 69/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.5201 - acc: 0.5627 - val_loss: 3.6091 - val_acc: 0.2263\n",
            "Epoch 70/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.4894 - acc: 0.5693 - val_loss: 3.7165 - val_acc: 0.2204\n",
            "Epoch 71/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.5092 - acc: 0.5684 - val_loss: 3.6961 - val_acc: 0.2263\n",
            "Epoch 72/150\n",
            "7155/7155 [==============================] - 0s 41us/step - loss: 1.4748 - acc: 0.5716 - val_loss: 3.7324 - val_acc: 0.2299\n",
            "Epoch 73/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.4659 - acc: 0.5769 - val_loss: 3.7993 - val_acc: 0.2165\n",
            "Epoch 74/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.4497 - acc: 0.5797 - val_loss: 3.8975 - val_acc: 0.2185\n",
            "Epoch 75/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.4646 - acc: 0.5802 - val_loss: 3.7656 - val_acc: 0.2188\n",
            "Epoch 76/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.4528 - acc: 0.5785 - val_loss: 3.7427 - val_acc: 0.2357\n",
            "Epoch 77/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.4494 - acc: 0.5768 - val_loss: 3.7519 - val_acc: 0.2361\n",
            "Epoch 78/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.4042 - acc: 0.5934 - val_loss: 3.7635 - val_acc: 0.2233\n",
            "Epoch 79/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.3753 - acc: 0.5996 - val_loss: 3.7072 - val_acc: 0.2263\n",
            "Epoch 80/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.3861 - acc: 0.5965 - val_loss: 3.7550 - val_acc: 0.2273\n",
            "Epoch 81/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.3998 - acc: 0.5927 - val_loss: 3.7946 - val_acc: 0.2240\n",
            "Epoch 82/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.4151 - acc: 0.5855 - val_loss: 3.7642 - val_acc: 0.2233\n",
            "Epoch 83/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.3774 - acc: 0.6013 - val_loss: 3.7885 - val_acc: 0.2233\n",
            "Epoch 84/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.3778 - acc: 0.5961 - val_loss: 3.8398 - val_acc: 0.2276\n",
            "Epoch 85/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.3409 - acc: 0.6055 - val_loss: 3.8403 - val_acc: 0.2292\n",
            "Epoch 86/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.3608 - acc: 0.5997 - val_loss: 3.8230 - val_acc: 0.2269\n",
            "Epoch 87/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.3534 - acc: 0.6039 - val_loss: 3.8997 - val_acc: 0.2155\n",
            "Epoch 88/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.3410 - acc: 0.6001 - val_loss: 3.9214 - val_acc: 0.2194\n",
            "Epoch 89/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.3231 - acc: 0.6134 - val_loss: 3.8908 - val_acc: 0.2243\n",
            "Epoch 90/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.3216 - acc: 0.6138 - val_loss: 3.9351 - val_acc: 0.2162\n",
            "Epoch 91/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.3071 - acc: 0.6129 - val_loss: 3.9816 - val_acc: 0.2175\n",
            "Epoch 92/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.3136 - acc: 0.6122 - val_loss: 3.9058 - val_acc: 0.2256\n",
            "Epoch 93/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.2900 - acc: 0.6235 - val_loss: 4.0059 - val_acc: 0.2250\n",
            "Epoch 94/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.2871 - acc: 0.6200 - val_loss: 3.9319 - val_acc: 0.2155\n",
            "Epoch 95/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.2954 - acc: 0.6207 - val_loss: 3.8930 - val_acc: 0.2269\n",
            "Epoch 96/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.2622 - acc: 0.6219 - val_loss: 3.8995 - val_acc: 0.2230\n",
            "Epoch 97/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.2842 - acc: 0.6184 - val_loss: 3.9183 - val_acc: 0.2331\n",
            "Epoch 98/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.2659 - acc: 0.6266 - val_loss: 3.9644 - val_acc: 0.2230\n",
            "Epoch 99/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.2200 - acc: 0.6359 - val_loss: 3.9261 - val_acc: 0.2230\n",
            "Epoch 100/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.2286 - acc: 0.6393 - val_loss: 3.9954 - val_acc: 0.2181\n",
            "Epoch 101/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.2607 - acc: 0.6254 - val_loss: 3.9527 - val_acc: 0.2181\n",
            "Epoch 102/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.2523 - acc: 0.6310 - val_loss: 4.0538 - val_acc: 0.2201\n",
            "Epoch 103/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.2119 - acc: 0.6435 - val_loss: 4.1413 - val_acc: 0.2191\n",
            "Epoch 104/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.2356 - acc: 0.6319 - val_loss: 4.0910 - val_acc: 0.2188\n",
            "Epoch 105/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.2439 - acc: 0.6282 - val_loss: 3.9891 - val_acc: 0.2227\n",
            "Epoch 106/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.1922 - acc: 0.6444 - val_loss: 3.9547 - val_acc: 0.2224\n",
            "Epoch 107/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.1976 - acc: 0.6423 - val_loss: 3.9550 - val_acc: 0.2276\n",
            "Epoch 108/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.2127 - acc: 0.6355 - val_loss: 4.0486 - val_acc: 0.2116\n",
            "Epoch 109/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.2045 - acc: 0.6393 - val_loss: 4.0233 - val_acc: 0.2204\n",
            "Epoch 110/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.2100 - acc: 0.6437 - val_loss: 4.0022 - val_acc: 0.2220\n",
            "Epoch 111/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.1876 - acc: 0.6436 - val_loss: 4.0723 - val_acc: 0.2361\n",
            "Epoch 112/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.2120 - acc: 0.6369 - val_loss: 3.9952 - val_acc: 0.2253\n",
            "Epoch 113/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.1886 - acc: 0.6472 - val_loss: 4.0131 - val_acc: 0.2305\n",
            "Epoch 114/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.2019 - acc: 0.6423 - val_loss: 4.1983 - val_acc: 0.2129\n",
            "Epoch 115/150\n",
            "7155/7155 [==============================] - 0s 37us/step - loss: 1.1577 - acc: 0.6552 - val_loss: 4.0595 - val_acc: 0.2240\n",
            "Epoch 116/150\n",
            "7155/7155 [==============================] - 0s 41us/step - loss: 1.1519 - acc: 0.6539 - val_loss: 4.0955 - val_acc: 0.2237\n",
            "Epoch 117/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.1493 - acc: 0.6553 - val_loss: 4.0720 - val_acc: 0.2315\n",
            "Epoch 118/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.1261 - acc: 0.6646 - val_loss: 4.1307 - val_acc: 0.2246\n",
            "Epoch 119/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.1225 - acc: 0.6672 - val_loss: 4.1398 - val_acc: 0.2201\n",
            "Epoch 120/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.1449 - acc: 0.6549 - val_loss: 4.0693 - val_acc: 0.2312\n",
            "Epoch 121/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.1290 - acc: 0.6584 - val_loss: 4.1630 - val_acc: 0.2224\n",
            "Epoch 122/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.1361 - acc: 0.6590 - val_loss: 4.1304 - val_acc: 0.2214\n",
            "Epoch 123/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.1295 - acc: 0.6619 - val_loss: 4.1170 - val_acc: 0.2312\n",
            "Epoch 124/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.0953 - acc: 0.6745 - val_loss: 4.1725 - val_acc: 0.2266\n",
            "Epoch 125/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.1258 - acc: 0.6633 - val_loss: 4.1603 - val_acc: 0.2224\n",
            "Epoch 126/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.1316 - acc: 0.6672 - val_loss: 4.1361 - val_acc: 0.2282\n",
            "Epoch 127/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.0840 - acc: 0.6721 - val_loss: 4.0942 - val_acc: 0.2292\n",
            "Epoch 128/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.1001 - acc: 0.6732 - val_loss: 4.1532 - val_acc: 0.2227\n",
            "Epoch 129/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.1106 - acc: 0.6668 - val_loss: 4.1762 - val_acc: 0.2243\n",
            "Epoch 130/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0894 - acc: 0.6802 - val_loss: 4.1147 - val_acc: 0.2318\n",
            "Epoch 131/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.0692 - acc: 0.6755 - val_loss: 4.1469 - val_acc: 0.2230\n",
            "Epoch 132/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0847 - acc: 0.6734 - val_loss: 4.1640 - val_acc: 0.2243\n",
            "Epoch 133/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0828 - acc: 0.6756 - val_loss: 4.2450 - val_acc: 0.2250\n",
            "Epoch 134/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.0671 - acc: 0.6795 - val_loss: 4.1884 - val_acc: 0.2172\n",
            "Epoch 135/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0895 - acc: 0.6690 - val_loss: 4.2740 - val_acc: 0.2253\n",
            "Epoch 136/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.0656 - acc: 0.6799 - val_loss: 4.2185 - val_acc: 0.2233\n",
            "Epoch 137/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.1093 - acc: 0.6668 - val_loss: 4.2804 - val_acc: 0.2175\n",
            "Epoch 138/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.0564 - acc: 0.6806 - val_loss: 4.2492 - val_acc: 0.2158\n",
            "Epoch 139/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.0905 - acc: 0.6704 - val_loss: 4.1898 - val_acc: 0.2273\n",
            "Epoch 140/150\n",
            "7155/7155 [==============================] - 0s 41us/step - loss: 1.1078 - acc: 0.6615 - val_loss: 4.2425 - val_acc: 0.2194\n",
            "Epoch 141/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.0894 - acc: 0.6693 - val_loss: 4.2289 - val_acc: 0.2246\n",
            "Epoch 142/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0380 - acc: 0.6864 - val_loss: 4.1947 - val_acc: 0.2289\n",
            "Epoch 143/150\n",
            "7155/7155 [==============================] - 0s 38us/step - loss: 1.0543 - acc: 0.6795 - val_loss: 4.2151 - val_acc: 0.2276\n",
            "Epoch 144/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0496 - acc: 0.6851 - val_loss: 4.1890 - val_acc: 0.2302\n",
            "Epoch 145/150\n",
            "7155/7155 [==============================] - 0s 41us/step - loss: 1.0299 - acc: 0.6907 - val_loss: 4.1721 - val_acc: 0.2318\n",
            "Epoch 146/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0687 - acc: 0.6771 - val_loss: 4.2733 - val_acc: 0.2211\n",
            "Epoch 147/150\n",
            "7155/7155 [==============================] - 0s 42us/step - loss: 1.0293 - acc: 0.6872 - val_loss: 4.2156 - val_acc: 0.2312\n",
            "Epoch 148/150\n",
            "7155/7155 [==============================] - 0s 40us/step - loss: 1.0488 - acc: 0.6881 - val_loss: 4.2643 - val_acc: 0.2276\n",
            "Epoch 149/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0249 - acc: 0.6911 - val_loss: 4.2168 - val_acc: 0.2305\n",
            "Epoch 150/150\n",
            "7155/7155 [==============================] - 0s 39us/step - loss: 1.0440 - acc: 0.6882 - val_loss: 4.3172 - val_acc: 0.2243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QD82N1laz5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}