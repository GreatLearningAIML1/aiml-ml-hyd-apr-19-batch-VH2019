{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIMP_APR19_Residency6_Project_BankChurn1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxRJxiKztzQz",
        "colab_type": "text"
      },
      "source": [
        "DEEP LEARNING -> Bank Customer Churn Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2PjUyMWt2Ss",
        "colab_type": "text"
      },
      "source": [
        "This project has 2 case studies. The first case study (described below - 30 points) covers concepts taught in Part 1 (first 8 hours of Neural networks basics).\n",
        "\n",
        "1st case study - Project 1:\n",
        "\n",
        "The case study is from an open source dataset from Kaggle. \n",
        "\n",
        "Link to the Kaggle project site:\n",
        "\n",
        "https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling (Links to an external site.)Links to an external site.\n",
        "\n",
        "Given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks?\n",
        "\n",
        "Data file - bank.csvView in a new window\n",
        "\n",
        " \n",
        "\n",
        "The points distribution for this case is as follows:\n",
        "\n",
        "Read the dataset\n",
        "Drop the columns which are unique for all users like IDs (2.5 points)\n",
        "Distinguish the feature and target set (2.5 points)\n",
        "Divide the data set into Train and test sets\n",
        "Normalize the train and test data (2.5 points)\n",
        "Initialize & build the model (10 points)\n",
        "Optimize the model (5 points)\n",
        "Predict the results using 0.5 as a threshold (5 points)\n",
        "Print the Accuracy score and confusion matrix (2.5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6n8xddlu-Mx",
        "colab_type": "text"
      },
      "source": [
        "1. Read the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-fFjVBPvxgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08ac7f35-0c95-4470-f28c-cbc531c84b45"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ6y8fBnvxjx",
        "colab_type": "code",
        "outputId": "fe77f1eb-abe0-4575-bf7e-3338b73a8c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAJaX9voAzLu",
        "colab_type": "code",
        "outputId": "b6a0ed65-2c17-47bf-fb35-7cd11702e451",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 40
        }
      },
      "source": [
        "from google.colab import files\n",
        "file=files.upload()\n",
        "bank_csv=pd.read_csv('bank.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-87d924a1-61c5-4497-8647-9154f8ced84d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-87d924a1-61c5-4497-8647-9154f8ced84d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ZfWD_nAzOf",
        "colab_type": "code",
        "outputId": "0b9ecc2b-6c67-4a8a-a0c1-9c4cfab9bef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "bank_csv.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1          2    15647311      Hill  ...               1       112542.58      0\n",
              "2          3    15619304      Onio  ...               0       113931.57      1\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWc8dHPXMg4z",
        "colab_type": "code",
        "outputId": "dfe985fa-0f16-42ea-a894-8c639b6481c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "bank_csv.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
              "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
              "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVn279GRWHBb",
        "colab_type": "code",
        "outputId": "86d3cc51-48c1-4cda-905d-98e6d3adda1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "bank_csv.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            "RowNumber          10000 non-null int64\n",
            "CustomerId         10000 non-null int64\n",
            "Surname            10000 non-null object\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null object\n",
            "Gender             10000 non-null object\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "Exited             10000 non-null int64\n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDi81iUMMqqs",
        "colab_type": "code",
        "outputId": "e4c8bd96-1cc0-4155-e926-8d86731d45c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bank_csv.CustomerId.nunique()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw4SBJRCvqgr",
        "colab_type": "text"
      },
      "source": [
        "2. Drop the columns which are unique for all users like IDs (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBzy-5GoLCD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bank_csv.drop(['CustomerId','RowNumber','Surname'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e96c7e4e-a81d-42b1-ea57-6a2d3ed73389",
        "id": "Picwur5W0CdG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "bank_csv.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
              "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n",
              "       'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g30RpSYu-QA",
        "colab_type": "text"
      },
      "source": [
        "3. Distinguish the feature and target set (2.5 points) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEbaddqU0V4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = bank_csv.iloc[:, 0:10].values\n",
        "y = bank_csv.iloc[:, 10].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCjL33s6SUxJ",
        "colab_type": "code",
        "outputId": "94402a77-6fad-47dc-dbc1-649695a67c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuzYOxRVa2Yd",
        "colab_type": "code",
        "outputId": "12cbf26a-850e-40ba-e401-a598c409ee5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiCBckBFlm9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Geography and Gender Column needs to be encoded\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-CXEOmTlnAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = LabelEncoder()\n",
        "X[:, 1] = le.fit_transform(X[:, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBhH3ZEIlnDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le1 = LabelEncoder()\n",
        "X[:, 2] = le1.fit_transform(X[:, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my6uGJOH1lWX",
        "colab_type": "code",
        "outputId": "19d1bae5-faef-46d1-8c32-4629ed3d8426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
        "feature = onehotencoder.fit_transform(X).toarray()\n",
        "X = X[:, 1:]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIkMqPYD11Ed",
        "colab_type": "code",
        "outputId": "56ac5f35-8e23-4eeb-b4f6-b665adefb6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 42, 2, 0.0, 1, 1, 1, 101348.88], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REvO69A7146M",
        "colab_type": "code",
        "outputId": "5a7ffcf7-868b-4771-dd74-09f4140cba1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTNLhMjvu-TA",
        "colab_type": "text"
      },
      "source": [
        "4. Divide the data set into Train and test sets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P00HwG13bSSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2GfHSN6SbyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3,random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1i_DoQbwzY4",
        "colab_type": "text"
      },
      "source": [
        "5. Normalize the train and test data (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGy1LxqfcCbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgitX0QAcCeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = Normalizer()\n",
        "Xtrain = transformer.fit_transform(Xtrain)\n",
        "Xtest = transformer.fit_transform(Xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTgS4J8lcCho",
        "colab_type": "code",
        "outputId": "860ab15f-00db-44f6-89eb-b9e8ab68461a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "Xtrain[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 0.00000000e+00, 1.76451673e-03, 3.81517130e-04,\n",
              "       0.00000000e+00, 9.53792825e-05, 4.76896413e-05, 0.00000000e+00,\n",
              "       9.99998365e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HbQHbSAQRD5",
        "colab_type": "code",
        "outputId": "7aef85f4-c38e-4942-d296-19240d27fbd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "Xtest[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 1.03031929e-05, 4.84250068e-04, 2.06063859e-05,\n",
              "       0.00000000e+00, 2.06063859e-05, 1.03031929e-05, 1.03031929e-05,\n",
              "       9.99999882e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5wxVrfYm7pR",
        "colab_type": "code",
        "outputId": "fc60e6be-431e-445b-af53-fd6398b9262f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(Xtrain.shape)\n",
        "print(Xtest.shape)\n",
        "print(ytrain.shape)\n",
        "print(ytest.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 9)\n",
            "(3000, 9)\n",
            "(7000,)\n",
            "(3000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK9fSL4Vu-WB",
        "colab_type": "text"
      },
      "source": [
        "6. Initialize & build the model (10 points) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9tA_HbG2wgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add Dense Layer which provides 2 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(2, activation='relu'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY0AnzvD2wjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build the graph\n",
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(6, activation='relu'))\n",
        "\n",
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(6, activation='relu'))\n",
        "\n",
        "\n",
        "#Add OUTPUT layer\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATZNPzRQnjqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the Neural Network\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJRzg60B4ma3",
        "colab_type": "code",
        "outputId": "689772b7-25dd-410a-f77c-c2407f744b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Execute the Graph\n",
        "model.fit(Xtrain, ytrain, validation_data=(Xtest, ytest),epochs=100,batch_size=10)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 3000 samples\n",
            "Epoch 1/100\n",
            "7000/7000 [==============================] - 2s 259us/sample - loss: 0.6207 - acc: 0.7896 - val_loss: 0.5708 - val_acc: 0.7910\n",
            "Epoch 2/100\n",
            "7000/7000 [==============================] - 1s 205us/sample - loss: 0.5395 - acc: 0.7986 - val_loss: 0.5275 - val_acc: 0.7910\n",
            "Epoch 3/100\n",
            "7000/7000 [==============================] - 1s 212us/sample - loss: 0.5121 - acc: 0.7986 - val_loss: 0.5154 - val_acc: 0.7910\n",
            "Epoch 4/100\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.5046 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 5/100\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.5028 - acc: 0.7986 - val_loss: 0.5126 - val_acc: 0.7910\n",
            "Epoch 6/100\n",
            "7000/7000 [==============================] - 1s 202us/sample - loss: 0.5025 - acc: 0.7986 - val_loss: 0.5127 - val_acc: 0.7910\n",
            "Epoch 7/100\n",
            "7000/7000 [==============================] - 1s 212us/sample - loss: 0.5025 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 8/100\n",
            "7000/7000 [==============================] - 1s 204us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 9/100\n",
            "7000/7000 [==============================] - 1s 204us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 10/100\n",
            "7000/7000 [==============================] - 2s 215us/sample - loss: 0.5025 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 11/100\n",
            "7000/7000 [==============================] - 2s 218us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 12/100\n",
            "7000/7000 [==============================] - 1s 204us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 13/100\n",
            "7000/7000 [==============================] - 1s 205us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 14/100\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 15/100\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 16/100\n",
            "7000/7000 [==============================] - 1s 205us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 17/100\n",
            "7000/7000 [==============================] - 1s 208us/sample - loss: 0.5025 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 18/100\n",
            "7000/7000 [==============================] - 1s 206us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 19/100\n",
            "7000/7000 [==============================] - 1s 206us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 20/100\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 21/100\n",
            "7000/7000 [==============================] - 1s 209us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 22/100\n",
            "7000/7000 [==============================] - 1s 210us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 23/100\n",
            "7000/7000 [==============================] - 1s 208us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 24/100\n",
            "7000/7000 [==============================] - 2s 247us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 25/100\n",
            "7000/7000 [==============================] - 2s 239us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 26/100\n",
            "7000/7000 [==============================] - 2s 246us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 27/100\n",
            "7000/7000 [==============================] - 2s 250us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 28/100\n",
            "7000/7000 [==============================] - 1s 207us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 29/100\n",
            "7000/7000 [==============================] - 1s 214us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 30/100\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 31/100\n",
            "7000/7000 [==============================] - 1s 206us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 32/100\n",
            "7000/7000 [==============================] - 1s 209us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 33/100\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 34/100\n",
            "7000/7000 [==============================] - 1s 207us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 35/100\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5127 - val_acc: 0.7910\n",
            "Epoch 36/100\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 37/100\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 38/100\n",
            "7000/7000 [==============================] - 1s 199us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 39/100\n",
            "7000/7000 [==============================] - 1s 205us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5127 - val_acc: 0.7910\n",
            "Epoch 40/100\n",
            "7000/7000 [==============================] - 2s 220us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 41/100\n",
            "7000/7000 [==============================] - 1s 202us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 42/100\n",
            "7000/7000 [==============================] - 1s 199us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 43/100\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 44/100\n",
            "7000/7000 [==============================] - 1s 205us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 45/100\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 46/100\n",
            "7000/7000 [==============================] - 1s 199us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 47/100\n",
            "7000/7000 [==============================] - 1s 207us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 48/100\n",
            "7000/7000 [==============================] - 1s 208us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 49/100\n",
            "7000/7000 [==============================] - 2s 226us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 50/100\n",
            "7000/7000 [==============================] - 2s 233us/sample - loss: 0.5025 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 51/100\n",
            "7000/7000 [==============================] - 2s 242us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 52/100\n",
            "7000/7000 [==============================] - 2s 227us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 53/100\n",
            "7000/7000 [==============================] - 2s 230us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 54/100\n",
            "7000/7000 [==============================] - 2s 223us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 55/100\n",
            "7000/7000 [==============================] - 1s 210us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 56/100\n",
            "7000/7000 [==============================] - 1s 202us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 57/100\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 58/100\n",
            "7000/7000 [==============================] - 1s 200us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 59/100\n",
            "7000/7000 [==============================] - 1s 196us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 60/100\n",
            "7000/7000 [==============================] - 1s 199us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 61/100\n",
            "7000/7000 [==============================] - 1s 204us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 62/100\n",
            "7000/7000 [==============================] - 1s 196us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 63/100\n",
            "7000/7000 [==============================] - 1s 202us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 64/100\n",
            "7000/7000 [==============================] - 1s 205us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 65/100\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.5025 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 66/100\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 67/100\n",
            "7000/7000 [==============================] - 1s 202us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 68/100\n",
            "7000/7000 [==============================] - 1s 194us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 69/100\n",
            "7000/7000 [==============================] - 1s 191us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 70/100\n",
            "7000/7000 [==============================] - 1s 198us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 71/100\n",
            "7000/7000 [==============================] - 1s 197us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 72/100\n",
            "7000/7000 [==============================] - 1s 204us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 73/100\n",
            "7000/7000 [==============================] - 1s 197us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 74/100\n",
            "7000/7000 [==============================] - 1s 194us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 75/100\n",
            "7000/7000 [==============================] - 1s 196us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 76/100\n",
            "7000/7000 [==============================] - 1s 206us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 77/100\n",
            "7000/7000 [==============================] - 1s 197us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 78/100\n",
            "7000/7000 [==============================] - 1s 196us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 79/100\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 80/100\n",
            "7000/7000 [==============================] - 1s 192us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 81/100\n",
            "7000/7000 [==============================] - 1s 192us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 82/100\n",
            "7000/7000 [==============================] - 1s 198us/sample - loss: 0.5025 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 83/100\n",
            "7000/7000 [==============================] - 1s 194us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 84/100\n",
            "7000/7000 [==============================] - 1s 200us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 85/100\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 86/100\n",
            "7000/7000 [==============================] - 1s 196us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 87/100\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 88/100\n",
            "7000/7000 [==============================] - 1s 195us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 89/100\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5129 - val_acc: 0.7910\n",
            "Epoch 90/100\n",
            "7000/7000 [==============================] - 1s 200us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 91/100\n",
            "7000/7000 [==============================] - 1s 195us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 92/100\n",
            "7000/7000 [==============================] - 1s 192us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 93/100\n",
            "7000/7000 [==============================] - 1s 195us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5127 - val_acc: 0.7910\n",
            "Epoch 94/100\n",
            "7000/7000 [==============================] - 1s 198us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 95/100\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 96/100\n",
            "7000/7000 [==============================] - 1s 197us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 97/100\n",
            "7000/7000 [==============================] - 1s 197us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 98/100\n",
            "7000/7000 [==============================] - 1s 200us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 99/100\n",
            "7000/7000 [==============================] - 1s 198us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n",
            "Epoch 100/100\n",
            "7000/7000 [==============================] - 1s 188us/sample - loss: 0.5024 - acc: 0.7986 - val_loss: 0.5128 - val_acc: 0.7910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3b25a3b6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdXZURm1F7U6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss is at 50% with 79.86% accuracy "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "132IiDWtu-ZQ",
        "colab_type": "text"
      },
      "source": [
        "7. Optimize the model (5 points) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot24Qhxu4BoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "model.compile(optimizer=sgd_optimizer, loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t060-9Q7v1Wq",
        "colab_type": "code",
        "outputId": "367c092c-963a-45d2-d398-5771673e4fbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Execute the Graph\n",
        "model.fit(Xtrain, ytrain, validation_data=(Xtest, ytest),epochs=100,batch_size=10)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 3000 samples\n",
            "Epoch 1/100\n",
            "7000/7000 [==============================] - 2s 264us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 2/100\n",
            "7000/7000 [==============================] - 1s 176us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 3/100\n",
            "7000/7000 [==============================] - 1s 172us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 4/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 5/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 6/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 7/100\n",
            "7000/7000 [==============================] - 1s 174us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 8/100\n",
            "7000/7000 [==============================] - 1s 174us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 9/100\n",
            "7000/7000 [==============================] - 1s 174us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 10/100\n",
            "7000/7000 [==============================] - 1s 167us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 11/100\n",
            "7000/7000 [==============================] - 1s 182us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 12/100\n",
            "7000/7000 [==============================] - 1s 174us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 13/100\n",
            "7000/7000 [==============================] - 1s 171us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 14/100\n",
            "7000/7000 [==============================] - 1s 171us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 15/100\n",
            "7000/7000 [==============================] - 1s 186us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 16/100\n",
            "7000/7000 [==============================] - 1s 166us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 17/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 18/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 19/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 20/100\n",
            "7000/7000 [==============================] - 1s 166us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 21/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 22/100\n",
            "7000/7000 [==============================] - 1s 182us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 23/100\n",
            "7000/7000 [==============================] - 1s 167us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 24/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 25/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 26/100\n",
            "7000/7000 [==============================] - 1s 179us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 27/100\n",
            "7000/7000 [==============================] - 1s 175us/sample - loss: 0.1609 - val_loss: 0.1653\n",
            "Epoch 28/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 29/100\n",
            "7000/7000 [==============================] - 1s 183us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 30/100\n",
            "7000/7000 [==============================] - 1s 177us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 31/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 32/100\n",
            "7000/7000 [==============================] - 1s 166us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 33/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 34/100\n",
            "7000/7000 [==============================] - 1s 166us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 35/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 36/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 37/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 38/100\n",
            "7000/7000 [==============================] - 1s 176us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 39/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 40/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 41/100\n",
            "7000/7000 [==============================] - 1s 172us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 42/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 43/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 44/100\n",
            "7000/7000 [==============================] - 1s 179us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 45/100\n",
            "7000/7000 [==============================] - 1s 167us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 46/100\n",
            "7000/7000 [==============================] - 1s 167us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 47/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 48/100\n",
            "7000/7000 [==============================] - 1s 172us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 49/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 50/100\n",
            "7000/7000 [==============================] - 1s 171us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 51/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 52/100\n",
            "7000/7000 [==============================] - 1s 176us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 53/100\n",
            "7000/7000 [==============================] - 1s 167us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 54/100\n",
            "7000/7000 [==============================] - 1s 164us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 55/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 56/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 57/100\n",
            "7000/7000 [==============================] - 1s 177us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 58/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 59/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 60/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 61/100\n",
            "7000/7000 [==============================] - 1s 174us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 62/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 63/100\n",
            "7000/7000 [==============================] - 1s 166us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 64/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 65/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 66/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 67/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 68/100\n",
            "7000/7000 [==============================] - 1s 164us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 69/100\n",
            "7000/7000 [==============================] - 1s 174us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 70/100\n",
            "7000/7000 [==============================] - 1s 174us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 71/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 72/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 73/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 74/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 75/100\n",
            "7000/7000 [==============================] - 1s 178us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 76/100\n",
            "7000/7000 [==============================] - 1s 182us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 77/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 78/100\n",
            "7000/7000 [==============================] - 1s 166us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 79/100\n",
            "7000/7000 [==============================] - 1s 175us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 80/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 81/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 82/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 83/100\n",
            "7000/7000 [==============================] - 1s 167us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 84/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 85/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 86/100\n",
            "7000/7000 [==============================] - 1s 167us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 87/100\n",
            "7000/7000 [==============================] - 1s 163us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 88/100\n",
            "7000/7000 [==============================] - 1s 172us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 89/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 90/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 91/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 92/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 93/100\n",
            "7000/7000 [==============================] - 1s 180us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 94/100\n",
            "7000/7000 [==============================] - 1s 181us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 95/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 96/100\n",
            "7000/7000 [==============================] - 1s 165us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 97/100\n",
            "7000/7000 [==============================] - 1s 171us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 98/100\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 99/100\n",
            "7000/7000 [==============================] - 1s 162us/sample - loss: 0.1609 - val_loss: 0.1654\n",
            "Epoch 100/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.1609 - val_loss: 0.1654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3b2593fe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uja9mUXuG2FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loss is at 16%, there is loss reduction by 34%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we2Lkc2iu-fh",
        "colab_type": "text"
      },
      "source": [
        "8. Predict the results using 0.5 as a threshold (5 points) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq47VruwIgQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ypred = model.predict(Xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTsDtPuJv2B0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model prediction\n",
        "prediction = model.predict(Xtest)\n",
        "Ypred = (Ypred > 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSvblqMdv2Ft",
        "colab_type": "code",
        "outputId": "ddaaf4b0-3f75-47c6-f0cd-61f2e8834aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#Print prediction\n",
        "print(prediction)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.20238924]\n",
            " [0.20238924]\n",
            " [0.20238924]\n",
            " ...\n",
            " [0.20238924]\n",
            " [0.20238924]\n",
            " [0.20238924]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLlL5_NkH-HI",
        "colab_type": "code",
        "outputId": "407b9465-9b99-4673-9b10-ee97453aac77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ytest[0]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mpIk4_Ou-jh",
        "colab_type": "text"
      },
      "source": [
        "9. Print the Accuracy score and confusion matrix (2.5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrDxcAtYv2tV",
        "colab_type": "code",
        "outputId": "ac1b2a42-6c8b-473c-ae03-a7c88bea7ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(ytest, Ypred)\n",
        "print(cm)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2373    0]\n",
            " [ 627    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE6CN6wgv2w6",
        "colab_type": "code",
        "outputId": "6e1e57bb-c9c0-48bb-a71e-8097766cedde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Visualizing confusion matrix\n",
        "pos, neg = cm\n",
        "tp, fp = pos\n",
        "fn, tn = neg\n",
        "print('True Positives:', tp)\n",
        "print('True Negatives:', tn)\n",
        "print('False Positives:', fp)\n",
        "print('False Negatives:', fn)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Positives: 2373\n",
            "True Negatives: 0\n",
            "False Positives: 0\n",
            "False Negatives: 627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BI_JHNStwaN",
        "colab_type": "code",
        "outputId": "f4288662-2ba4-4a38-9448-a8e50b00088b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Accuracy rate of confusion matrix\n",
        "print('Accuracy:', (tp+tn)/(tp+tn+fp+fn))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPjqr6OeKTDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accuracy is 79%"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}